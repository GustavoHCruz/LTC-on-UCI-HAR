{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "from torch import Tensor\n",
    "import torch.nn as nn\n",
    "from ncps.wirings import AutoNCP\n",
    "from ncps.torch import LTC\n",
    "import pytorch_lightning as pl\n",
    "import torch.utils.data as data\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "\n",
    "sys.path.append(os.path.abspath(\"funcs\"))\n",
    "\n",
    "from timer_callback import TimingCallback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting the CUDA float32 precision. Can be changed to \"high\" if needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_float32_matmul_precision(\"medium\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "np.random.seed(seed)\n",
    "pl.seed_everything(seed, workers=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reading the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = np.loadtxt('dataset/uci-har/train/X_train.txt')\n",
    "train_y = np.loadtxt('dataset/uci-har/train/y_train.txt').astype(int)\n",
    "\n",
    "test_x = np.loadtxt('dataset/uci-har/test/X_test.txt')\n",
    "test_y = np.loadtxt('dataset/uci-har/test/y_test.txt').astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming the samples and labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization on samples\n",
    "\n",
    "scaler = StandardScaler()\n",
    "train_x = scaler.fit_transform(train_x)\n",
    "test_x = scaler.fit_transform(test_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the labels to a label-positional list\n",
    "\n",
    "conversion_dict = {1: [1, 0, 0, 0, 0, 0], 2: [0, 1, 0, 0, 0, 0], \n",
    "                   3: [0, 0, 1, 0, 0, 0], 4: [0, 0, 0, 1, 0, 0], \n",
    "                   5: [0, 0, 0, 0, 1, 0], 6: [0, 0, 0, 0, 0, 1]}\n",
    "\n",
    "conversion_result = []\n",
    "for e in train_y:\n",
    "  conversion_result.append(conversion_dict[e])\n",
    "\n",
    "train_y = np.array(conversion_result)\n",
    "\n",
    "conversion_result = []\n",
    "for e in test_y:\n",
    "  conversion_result.append(conversion_dict[e])\n",
    "\n",
    "test_y_loader = np.array(conversion_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding a batch dimension on samples data\n",
    "\n",
    "train_x = np.expand_dims(train_x, axis=0).astype(np.float32)\n",
    "test_x = np.expand_dims(test_x, axis=0).astype(np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining a possible crop on data and defining values. Can be used to speed up the training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crop_rate = 0.0\n",
    "original_len = train_x.shape[1]\n",
    "final_len = int(original_len * (1-crop_rate))\n",
    "test_len = test_x.shape[1]\n",
    "\n",
    "train_x = train_x[:final_len]\n",
    "train_y = train_y[:final_len]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming data into PyTorch Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming into PyTorch Tensors\n",
    "\n",
    "train_x = Tensor(train_x)\n",
    "train_y = Tensor(train_y.reshape(1, final_len, 6))\n",
    "test_x = Tensor(test_x)\n",
    "test_y_loader = Tensor(test_y_loader.reshape(1, test_y.shape[0], 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should be two lists like [Batch, Data Amount, Sample/Label]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "print(train_y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining loaders, models phases and model configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = data.DataLoader(data.TensorDataset(train_x, train_y), shuffle=True, num_workers=16, persistent_workers=True)\n",
    "test_dataloader = data.DataLoader(data.TensorDataset(test_x, test_y_loader), shuffle=True, num_workers=16, persistent_workers=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightningModule for training a RNNSequence module\n",
    "\n",
    "class SequenceLearner(pl.LightningModule):\n",
    "  def __init__(self, model, lr):\n",
    "    super().__init__()\n",
    "    self.model = model\n",
    "    self.lr = lr\n",
    "\n",
    "  def training_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    y_hat, _ = self.model.forward(x)\n",
    "    y_hat = y_hat.view_as(y)\n",
    "    loss = nn.MSELoss()(y_hat, y)\n",
    "    self.log(\"train_loss\", loss, prog_bar=True)\n",
    "    return {\"loss\": loss}\n",
    "\n",
    "  def validation_step(self, batch, batch_idx):\n",
    "    x, y = batch\n",
    "    y_hat, _ = self.model.forward(x)\n",
    "    y_hat = y_hat.view_as(y)\n",
    "    loss = nn.MSELoss()(y_hat, y)\n",
    "\n",
    "    self.log(\"val_loss\", loss, prog_bar=True)\n",
    "    return loss\n",
    "\n",
    "  def test_step(self, batch, batch_idx):\n",
    "    # Here we just reuse the validation_step for testing\n",
    "    return self.validation_step(batch, batch_idx)\n",
    "\n",
    "  def configure_optimizers(self):\n",
    "    return torch.optim.Adam(self.model.parameters(), lr=self.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_features = 6 # Output\n",
    "in_features = 561 # Input\n",
    "\n",
    "wiring = AutoNCP(64, out_features)\n",
    "\n",
    "ltc_model = LTC(in_features, wiring, batch_first=True)\n",
    "learn = SequenceLearner(ltc_model, lr=0.01)\n",
    "\n",
    "log_dir = f\"logs\"\n",
    "logger = CSVLogger(log_dir, name=\"r_ex001\")\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    log_every_n_steps=1,\n",
    "    logger=logger,\n",
    "    max_epochs=200,\n",
    "    gradient_clip_val=1,  # Clip gradient to stabilize training\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(learn, dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.test(learn, test_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving (or loading) the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the trained model\n",
    "\n",
    "torch.save(ltc_model, \"models/r_ex001.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluating the model on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining each label meaning\n",
    "\n",
    "translate_dict = {0: \"Walking\", 1: \"Walking_Upstairs\", 2: \"Walking_Downstairs\", 3: \"Sitting\", 4: \"Standing\", 5: \"Laying\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using the model to predict data\n",
    "\n",
    "prediction_results = ltc_model(test_x)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hits = 0 # Counter for the amount of correct awnsers\n",
    "\n",
    "for i in range(0, prediction_results.shape[0]):\n",
    "  prediction = np.array(prediction_results[i].tolist()).argmax()\n",
    "  label_response = test_y[i] - 1 # -1 to fit dictionary starting in 0\n",
    "\n",
    "  if translate_dict[prediction] == translate_dict[label_response]:\n",
    "    hits += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Model's Accuracy On Test Data: {hits/test_len:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
